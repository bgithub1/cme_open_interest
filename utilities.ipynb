{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful utilities for merging data and graphing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "def str_to_date(d):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d),'%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "    return dt\n",
    "\n",
    "# Make important folders\n",
    "TEMP_FOLDER = './temp_folder'\n",
    "try:\n",
    "    os.mkdir(TEMP_FOLDER)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f'{TEMP_FOLDER}/cot')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f'{TEMP_FOLDER}/zip')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Paths to main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_save_path = './etf_cap_hist.csv'\n",
    "cot_save_path = './cot_history.csv'\n",
    "oi_save_path = './cme_open_interest.csv'\n",
    "SAVED_IMAGE_FOLDER = f'{TEMP_FOLDER}/saved_images'\n",
    "try:\n",
    "    os.mkdir(SAVED_IMAGE_FOLDER)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pandasql to do merges that pandas alone cannot do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psql_merge(df1_name,col1_low,col1_high,df2_name,col2_low,col2_high):\n",
    "    q = f\"\"\"select * from {df1_name}\n",
    "    join {df2_name} on {df1_name}.{col1_low} >= {df2_name}.{col2_low} \n",
    "         and {df1_name}.{col1_high} < {df2_name}.{col2_high} \n",
    "    \"\"\"\n",
    "    pysqldf = lambda q: psql.sqldf(q, globals())\n",
    "    df3 = pysqldf(q)\n",
    "    return df3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_pandas uses df.plot to plot either lines or bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pandas(df_in,x_column,num_of_x_ticks=20,bar_plot=False):\n",
    "    '''\n",
    "    '''\n",
    "    df_cl = df_in.copy()\n",
    "    df_cl.index = list(range(len(df_cl)))\n",
    "    df_cl = df_cl.drop_duplicates()\n",
    "    xs = list(df_cl[x_column])\n",
    "    df_cl[x_column] = df_cl[x_column].apply(lambda i:str(i))\n",
    "\n",
    "    x = list(range(len(df_cl)))\n",
    "    n = len(x)\n",
    "    s = num_of_x_ticks\n",
    "    x_indices = x[::n//s][::-1]\n",
    "    x_labels = [str(t) for t in list(df_cl.iloc[x_indices][x_column])]\n",
    "    ycols = list(filter(lambda c: c!=x_column,df_cl.columns.values))\n",
    "    all_cols = [x_column] + ycols\n",
    "    if bar_plot:\n",
    "        ax = df_cl.plot.bar()\n",
    "    else:\n",
    "        if len(ycols)>1:\n",
    "            ax = df_cl[ycols].plot(secondary_y=ycols[1:],figsize=(16,10))\n",
    "        else:\n",
    "            ax = df_cl[ycols].plot(figsize=(16,10))\n",
    "\n",
    "    ax.set_xticks(x_indices)\n",
    "    ax.set_xticklabels(x_labels, rotation='vertical')\n",
    "    ax.grid()\n",
    "    return ax.get_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a large DataFrame by calling plot_pandas over slices of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plot(df,x_column,save_file_prefix,save_image_folder=SAVED_IMAGE_FOLDER,dates_per_plot=100,num_of_x_ticks=20,bar_plot=False):\n",
    "    plots = int(len(df)/dates_per_plot) + 1 if len(df) % dates_per_plot > 0 else 0\n",
    "    f = plt.figure()\n",
    "    image_names = []\n",
    "    for p in range(plots):\n",
    "        low_row = p * dates_per_plot\n",
    "        high_row = low_row + dates_per_plot\n",
    "        df_sub = df.iloc[low_row:high_row]\n",
    "        fig = plot_pandas(df_sub,x_column,num_of_x_ticks=num_of_x_ticks,bar_plot= bar_plot)\n",
    "        image_name = f'{save_image_folder}/{save_file_prefix}_{p+1}.png'\n",
    "        fig.savefig(image_name)\n",
    "        image_names.append(image_name)\n",
    "    return image_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Create A DataFrame using random normal data, and then test the above utility methods.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 2 random DataFrames that will be merged using ```psql_merge```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random open interest and price data\n",
    "random_open_interest = 100000 * (np.random.randn(1000)+1)\n",
    "random_prices = 20 * (np.random.randn(1000)+1)\n",
    "\n",
    "# create a bunch of weekday dates\n",
    "dt_beg = datetime.datetime(2014,1,1)\n",
    "dt_end = datetime.datetime(2019,1,1)\n",
    "dates_no_weekends = pd.bdate_range(dt_beg, dt_end)[-1000:]\n",
    "\n",
    "# get all of the fridays\n",
    "all_fridays = np.array(list(filter(lambda d: d.weekday()==4,dates_no_weekends)))\n",
    "current_friday_index = 0\n",
    "fridays = []\n",
    "\n",
    "# for each date in dates_no_weekends, get the friday date of that week\n",
    "for d in dates_no_weekends:\n",
    "    if current_friday_index < len(all_fridays) and (all_fridays[current_friday_index] - d).days <0:\n",
    "        current_friday_index += 1\n",
    "    cf = all_fridays[current_friday_index] if current_friday_index < len(all_fridays) else \\\n",
    "            all_fridays[-1] + datetime.timedelta(7)\n",
    "    fridays.append(cf)\n",
    "yyyymmdd_dates = [int(str(d)[0:4]+str(d)[5:7]+str(d)[8:10]) for d in dates_no_weekends]\n",
    "yyyymmdd_fridays = [int(str(d)[0:4]+str(d)[5:7]+str(d)[8:10]) for d in fridays]\n",
    "\n",
    "# create a DataFrame with the random data, the dates, and the fridays\n",
    "df_random = pd.DataFrame({'nav':random_prices,'open_interest':random_open_interest,'trade_date':yyyymmdd_dates,'friday_date':yyyymmdd_fridays,'friday':fridays})\n",
    "\n",
    "# create another DataFrame, that has weekly average prices for the data in df_random\n",
    "df_friday_avg = df_random[['friday','nav']].groupby('friday',as_index=False).mean()\n",
    "df_friday_avg = df_friday_avg.rename(columns = {'nav':'friday_nav'})\n",
    "this_fridays = [int(str(d)[0:4]+str(d)[5:7]+str(d)[8:10]) for d in list(df_friday_avg.friday)]\n",
    "next_fridays = list(df_friday_avg[1:].friday) + [df_friday_avg.iloc[0-1].friday + datetime.timedelta(7)]\n",
    "next_yyyymmdd_fridays = [int(str(d)[0:4]+str(d)[5:7]+str(d)[8:10]) for d in next_fridays]\n",
    "df_friday_avg['this_friday_date'] = this_fridays\n",
    "df_friday_avg['next_friday_date'] = next_yyyymmdd_fridays\n",
    "df_friday_avg = df_friday_avg[['this_friday_date','next_friday_date','friday_nav']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the 2 random DataFrames using ```psql_merge```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = psql_merge('df_random','trade_date','trade_date',\n",
    "                      'df_friday_avg','this_friday_date','next_friday_date')\n",
    "df_merged.tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pandas(df_in=df_merged[['trade_date','nav','open_interest']][-200:],x_column='trade_date');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = multi_plot(df_merged[['trade_date','nav','open_interest']],'trade_date','random_nav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge images into 1 vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs    = [ Image.open(i) for i in image_names ]\n",
    "# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "# for a vertical stacking it is simple: use vstack\n",
    "# imgs_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "imgs_comb = np.vstack( (np.asarray(i) for i in imgs ) )\n",
    "imgs_comb = Image.fromarray( imgs_comb)\n",
    "save_file = f\"{SAVED_IMAGE_FOLDER}/random_nav_all.png\"\n",
    "imgs_comb.save( save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Save this workbook as a py module (mac/linux only)\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert utilities.ipynb --to python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
