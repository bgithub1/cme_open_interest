{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build history of ETF shares outstanding and of commodity COTs\n",
    "\n",
    "### For ETF histories:\n",
    "Several companies that manage ETFs provide histores of the NAVs and shares outstanding of their ETF products.  This notebook fetchs that history data from those websites, and assembles a Pandas DataFrame with columns:\n",
    "1. symbol: like SPY or XLE\n",
    "2. date: a datetime.datetime object\n",
    "3. nav: the funds nav for that date\n",
    "4. shares: the shares outstanding at the end of that date\n",
    "5. pc: the percent change of those shares outstanding\n",
    "6. share_diff: the absolute change of those shares outstanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import datetime\n",
    "import jupyter_utilities as ju\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "def str_to_date(d):\n",
    "    try:\n",
    "        dt = datetime.datetime.strptime(str(d),'%Y-%m-%d')\n",
    "    except:\n",
    "        return None\n",
    "    return dt\n",
    "\n",
    "# Make important folders\n",
    "TEMP_FOLDER = './temp_folder'\n",
    "try:\n",
    "    os.mkdir(TEMP_FOLDER)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f'{TEMP_FOLDER}/cot')\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(f'{TEMP_FOLDER}/zip')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ju)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## First, decide if you want to re-create the ETF and COT data, or just retrieve the previously saved data DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_ETF_DATA = True\n",
    "# CREATE_COT_DATA = True\n",
    "etf_save_path = './etf_cap_hist.csv'\n",
    "# cot_save_path = './cot_history.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Retrieve data from iShares\n",
    "Currently, you must physically download each etf history because iShares does not support csv downloads for the commoditiy ETFs.  For other funds, they do.\n",
    "\n",
    "As an example, to process the iShares SLV (silver etf) download:\n",
    "1. Download the file from the url \"https://www.ishares.com/us/products/239855/ishares-silver-trust-fund/1521942788811.ajax?fileType=xls&fileName=iShares-Silver-Trust_fund&dataType=fund\" to a local folder;\n",
    "2. That url is actually an xml file which Microsoft Excel can convert into an xls workbook;\n",
    "3. Open that file in Microsoft Excel;\n",
    "4. Save the \"Historical\" worksheet as a csv with the file name 'etf_history.csv', where etf is something like \"slv\".\n",
    "  * **Make sure you save the file in the folder that contains this jupyter Noteboook**\n",
    "5. Execute the code below.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CREATE_ETF_DATA:\n",
    "    ishares_symbol_list = ['SLV','AGG']\n",
    "    ishares_csv_list = [\"./slv_history.csv\",'./agg_history.csv']\n",
    "    df_ishares = None\n",
    "    for i in range(len(ishares_symbol_list)):\n",
    "        url = ishares_csv_list[i]\n",
    "        isym = ishares_symbol_list[i]\n",
    "        df_temp = pd.read_csv(url)\n",
    "        df_temp['symbol'] = isym\n",
    "        if df_ishares is None:\n",
    "            df_ishares = df_temp.copy()\n",
    "        else:\n",
    "            df_ishares = df_ishares.append(df_temp)\n",
    "    df_ishares.head() \n",
    "    def ishares_date(d):\n",
    "        try:\n",
    "            dt = datetime.datetime.strptime(str(d),'%b %d, %Y')\n",
    "        except:\n",
    "            return None\n",
    "        return dt\n",
    "    df_ishares['date'] = df_ishares['As Of'].apply(ishares_date)\n",
    "    df_ishares = df_ishares.rename(columns = {'NAV per Share':'nav','Shares Outstanding':'shares'})\n",
    "    df_ishares = df_ishares[['symbol','date','nav','shares']]\n",
    "    df_ishares = df_ishares[~df_ishares.date.isnull()].sort_values(['symbol','date'])\n",
    "    df_ishares.index = list(range(len(df_ishares)))\n",
    "    df_ishares.shares = df_ishares.shares.apply(lambda s:float(str(s).replace(',','')))\n",
    "    df_ishares.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Retrieve data from ProFunds using the url from accounts.profunds\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_ETF_DATA:\n",
    "    profunds_symbol_list = ['UCO']\n",
    "    df_profunds = None\n",
    "    for psym in profunds_symbol_list:\n",
    "        url = f\"https://accounts.profunds.com/etfdata/ByFund/{psym}-historical_nav.csv\"\n",
    "        df_temp = pd.read_csv(url)\n",
    "        df_temp['symbol'] = psym\n",
    "        if df_profunds is None:\n",
    "            df_profunds = df_temp.copy()\n",
    "        else:\n",
    "            df_profunds = df_profunds.append(df_temp)\n",
    "    df_profunds.head()\n",
    "    def profunds_date(d):\n",
    "        try:\n",
    "            dt = datetime.datetime.strptime(str(d),'%m/%d/%Y')\n",
    "        except:\n",
    "            return None\n",
    "        return dt\n",
    "    df_profunds.columns.values,df_profunds.head()\n",
    "    df_profunds['date'] = df_profunds.Date.apply(profunds_date)\n",
    "    df_profunds = df_profunds.rename(columns = {'NAV':'nav','Shares Outstanding (000)':'shares'})\n",
    "    df_profunds = df_profunds[['symbol','date','nav','shares']]\n",
    "    df_profunds = df_profunds[~df_profunds.date.isnull()].sort_values(['symbol','date'])\n",
    "    df_profunds.index = list(range(len(df_profunds)))\n",
    "    df_profunds.shares = df_profunds.shares.apply(lambda s:float(str(s).replace(',','')))\n",
    "    df_profunds.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Retrieve ETF data for multiple ETFs from us.spdrs.com\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CREATE_ETF_DATA:\n",
    "    spdr_symbol_list = ['GLD','SPY','XLB','XLE','XLF','XLI','XLK','XLP','XLU']\n",
    "    df_spdr = None\n",
    "    for ssym in spdr_symbol_list:\n",
    "        url = f'https://us.spdrs.com/site-content/xls/{ssym}_HistoricalNav.xls?fund={ssym}&docname=Most+Recent+NAV+%2F+NAV+History&onyx_code1=&onyx_code2='\n",
    "    #     df_temp = pd.read_excel('https://us.spdrs.com/site-content/xls/SPY_HistoricalNav.xls?fund=SPY&docname=Most+Recent+NAV+%2F+NAV+History&onyx_code1=&onyx_code2=',skiprows=3)\n",
    "        df_temp = pd.read_excel(url,skiprows=3)\n",
    "        df_temp['symbol'] = ssym\n",
    "        if df_spdr is None:\n",
    "            df_spdr = df_temp.copy()\n",
    "        else:\n",
    "            df_spdr = df_spdr.append(df_temp)\n",
    "    def spdr_date(d):\n",
    "        try:\n",
    "            dt = datetime.datetime.strptime(str(d),'%d-%b-%Y')\n",
    "        except:\n",
    "            return None\n",
    "        return dt\n",
    "    df_spdr['date'] = df_spdr.Date.apply(spdr_date)\n",
    "    df_spdr = df_spdr.rename(columns = {'Nav':'nav','Shares Outstanding':'shares'})\n",
    "    df_spdr = df_spdr[['symbol','date','nav','shares']]\n",
    "    df_spdr = df_spdr[~df_spdr.date.isnull()].sort_values(['symbol','date'])\n",
    "    df_spdr.index = list(range(len(df_spdr)))\n",
    "    df_spdr.shares = df_spdr.shares.apply(lambda s:float(str(s).replace(',','')))\n",
    "    df_spdr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Fetch invesco ETF's from yahoo.  \n",
    "1. There is no \"shares\" data on the Invesco site, so we will use yahoo to just get NAV's, and set shares = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_ETF_DATA:\n",
    "    invesco_symbols = [f'FX{l}' for l in 'ABCEF']\n",
    "\n",
    "    df_invesco = None\n",
    "    for invesco_symbol in invesco_symbols:\n",
    "        df_temp = ju.fetch_history(invesco_symbol,datetime.datetime(2010, 1, 1), datetime.datetime.now())\n",
    "        df_temp['symbol'] = invesco_symbol\n",
    "        df_temp.date = df_temp.date.apply(ju.str_to_date)\n",
    "        df_temp['shares'] = 0\n",
    "        df_temp = df_temp.rename(columns={'close':'nav'})\n",
    "        df_temp = df_temp[['symbol','date','nav','shares']]\n",
    "        if df_invesco is None:\n",
    "            df_invesco = df_temp.copy()\n",
    "        else:\n",
    "            df_invesco = df_invesco.append(df_temp)\n",
    "    df_invesco.tail()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Combine the 3 separate dataframes into one and save it\n",
    "1. Append df_ishares, df_profunds and df_spdr rows together;\n",
    "2. Save the combined DataFrame to ./etf_cap_hist.csv;\n",
    "3. Read that csv back into the DataFrame dff\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CREATE_ETF_DATA:\n",
    "    df_all = df_ishares.copy()\n",
    "    df_all = df_all.append(df_profunds,ignore_index=True)\n",
    "    df_all = df_all.append(df_spdr,ignore_index=True)\n",
    "    df_all = df_all.append(df_invesco,ignore_index=True)\n",
    "    df_all.index = list(range(len(df_all)))\n",
    "    df_all.to_csv(etf_save_path,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_all.symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create the following columns:\n",
    "1. pc: shares daily percent change\n",
    "2. share_diff: daily difference from the shares column\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff  = pd.read_csv(etf_save_path)\n",
    "dff['date'] = dff.date.apply(str_to_date)\n",
    "df_fund_flows = dff.copy()\n",
    "df_fund_flows['shares'] = df_fund_flows.shares.apply(lambda s:float(str(s).replace(',','')))\n",
    "df_fund_flows = df_fund_flows.sort_values(['symbol','date'])\n",
    "symbol_list = list(set(df_fund_flows.symbol))\n",
    "df_final = None\n",
    "for sym in symbol_list:\n",
    "    df_this_sym= df_fund_flows[df_fund_flows.symbol==sym]\n",
    "    df_this_sym['pc'] = df_this_sym.shares.pct_change()\n",
    "    df_this_sym['share_diff'] = df_this_sym.shares.diff()\n",
    "    df_this_sym = df_this_sym[df_this_sym.pc.notnull()]\n",
    "    if df_final is None:\n",
    "        df_final = df_this_sym.copy()\n",
    "    else:\n",
    "        df_final = df_final.append(df_this_sym)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create the group_by Dataframes:\n",
    "1. df_pc_gb: shows the min and max per symbol of the pc column;\n",
    "2. df_share_diff_gb: shows the min and max per symbol of the share_diff column.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_beg = datetime.datetime.now() - datetime.timedelta(1000)\n",
    "df_final2 = df_final[(df_final.date>dt_beg)]\n",
    "df_pc = df_final2[['symbol','pc']] \n",
    "df_pc_gb = df_pc.groupby('symbol',as_index=False).agg({'pc':[min,max]})\n",
    "df_pc_gb.columns = ['symbol'] + [ t[0]+ '_' + t[1] for t in df_pc_gb.columns.values[1:]]\n",
    "df_share_diff = df_final2[['symbol','share_diff']] \n",
    "df_share_diff_gb = df_share_diff.groupby('symbol',as_index=False).agg({'share_diff':[min,max]})\n",
    "df_share_diff_gb.columns = ['symbol'] + [ t[0]+ '_' + t[1] for t in df_share_diff_gb.columns.values[1:]]\n",
    "df_pc_gb,df_share_diff_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final2.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create a DataFrame that has the pc of each security in a separate column.\n",
    "This dataframe will make it easy to graph histograms of the pc values\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc_all = None\n",
    "for sym in list(set(df_final2.symbol)):\n",
    "    df_temp = df_final2[df_final2.symbol==sym][['date','pc']]\n",
    "    df_temp = df_temp.rename(columns={'pc':sym})\n",
    "    if df_pc_all is None:\n",
    "        df_pc_all = df_temp.copy()\n",
    "    else:\n",
    "        df_pc_all = df_pc_all.merge(df_temp,how='inner',on='date')\n",
    "df_pc_all.index = df_pc_all.date\n",
    "df_pc_all = df_pc_all[list(filter(lambda c:'date' not in c,df_pc_all.columns.values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc_all.columns.values,df_pc_all.as_matrix().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Graph histograms of the pc column\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_pc_all.hist(bins=100,figsize=(20,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show frequency of outlier changes in shares outstanding in GLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "djan1 = datetime.datetime(2018,1,1)\n",
    "djan2 = datetime.datetime(2019,2,28)\n",
    "c1 = df_final2.symbol=='GLD'\n",
    "c2 = df_final2.date>=djan1\n",
    "c3 = df_final2.date<=djan2\n",
    "c4 = df_final2.pc >= .009\n",
    "allc = (c1) & (c2) & (c3) & (c4)\n",
    "df_final2[allc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
