{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import os,sys\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "import pandas_datareader.data as pdr\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a python function to access CSV data from Intrinio, and put it into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_intrinio(stk,start_date=None,end_date=None):\n",
    "    sd = '2016-01-01' if start_date is None else start_date\n",
    "    ed = str(datetime.datetime.now())[0:10]\n",
    "    try:\n",
    "        url = f'https://api.intrinio.com/prices.csv?start_date={sd}&end_date={ed}&identifier={stk}&api_key=OmU1NmEzYTU1Yjg3N2NjYWRiOWFjM2Y2OGYzMWNlMDcx'\n",
    "        req = urllib.request.Request(url)\n",
    "        f = urllib.request.urlopen(req)\n",
    "    except Exception:\n",
    "        f = urllib.request.urlopen(req)\n",
    "    alines = f.read().decode('utf-8')        \n",
    "    csv = alines.split('\\n')[1:]\n",
    "    handle = io.StringIO('\\n'.join(csv))\n",
    "    df = pd.read_csv(handle)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sym = 'AAPL'\n",
    "df1 = get_from_intrinio(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show it's done using yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_history(symbol,dt_beg,dt_end):\n",
    "    df = pdr.DataReader(symbol, 'yahoo', dt_beg, dt_end)\n",
    "    df['Date'] = df.index\n",
    "    df.Date = df.Date.astype(str).str.slice(0,10)\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "    df.index = list(range(len(df)))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyis of gap up's and downs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in tqdm(list(df_comp3.Symbol.values)):\n",
    "    time.sleep(.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exch = 'nyse'\n",
    "home_dir = str(pathlib.Path.home())\n",
    "df_comp = pd.read_csv(f'{home}/downloads/{exch}_companylist.csv')\n",
    "df_comp.columns = [c.strip() for c in df_comp.columns.values]\n",
    "num_cols = ['MarketCap','LastSale']\n",
    "for c in num_cols:\n",
    "    df_comp[c] = df_comp[c].astype(str).str.replace(',','').astype(float)\n",
    "df_comp2 = df_comp[(df_comp.MarketCap>100000000) & (df_comp.MarketCap<2000000000)]\n",
    "df_comp2 = df_comp2[df_comp2.LastSale<=30]\n",
    "print(f'len(df_comp2): {len(df_comp2)}')\n",
    "df_comp3 = df_comp2[['Symbol']+num_cols].sort_values('MarketCap')\n",
    "df_comp3.tail(20)\n",
    "dict_df_smallcap = {}\n",
    "sym_list = list(df_comp3.Symbol.values)\n",
    "for sym in tqdm(sym_list):\n",
    "    print(f'fetching {sym}')\n",
    "    try:\n",
    "        df_temp = fetch_history(sym,'2016-01-01','2019-06-14')\n",
    "        dict_df_smallcap[sym] = df_temp\n",
    "    except:\n",
    "        print(f'no data for {sym}')\n",
    "print(f'total rows: {np.array([len(dict_df_smallcap[k]) for k in dict_df_smallcap.keys()]).sum()}')\n",
    "dict_large_pchg = {}\n",
    "for k in dict_df_smallcap:\n",
    "    dft = dict_df_smallcap[k]\n",
    "    dft['Symbol'] = k\n",
    "    dft['prev_close'] = dft.Close.shift(1)\n",
    "    dft['pchg'] = dft.Close.pct_change()\n",
    "    dft2 = dft[dft.pchg.abs()>.49]\n",
    "    if len(dft2)>0:\n",
    "        dict_large_pchg[k] = dft2\n",
    "print(f'len of large pchgs: {len(dict_large_pchg)}')\n",
    "# print(dict_large_pchg[list(dict_large_pchg.keys())[0]])\n",
    "df_large_chg = dict_large_pchg[list(dict_large_pchg.keys())[0]]\n",
    "for k in list(dict_large_pchg.keys())[1:]:\n",
    "    df_large_chg = df_large_chg.append(dict_large_pchg[k])\n",
    "    df_large_chg.index = list(range(len(df_large_chg)))\n",
    "df_large_chg = df_large_chg.sort_values(['Symbol','Date']) \n",
    "df_large_chg.to_csv(f'{home_dir}/downloads/df_large_chg_{exch}.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
