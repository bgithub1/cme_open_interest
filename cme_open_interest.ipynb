{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and display cme open interest history from ftp.cmegroup.com daily xlsx files\n",
    "\n",
    "(This workbook executes several Bash commands, so the workbook will not work using Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pypg.pg_pandas as pg\n",
    "import os,sys\n",
    "import openpyxl as pyxl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl import load_workbook\n",
    "ftp_folder = 'ftp://ftp.cmegroup.com/daily_volume'\n",
    "temp_folder = './temp_folder'\n",
    "local_folder = f'{temp_folder}/cme_daily_volume'\n",
    "EXAMPLE_COMMODITY_ETFS = ['GLD','SLV','USO']\n",
    "REFRESH_ETF_PRICES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Set year to fetch from ftp site using wget\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P {local_folder}  {ftp_folder}/{file_name}\n",
    "year = '2019'\n",
    "\n",
    "csv_fn = f'{temp_folder}/cme_open_interest_%s' %(str(year))\n",
    "# fetch the data if the below is True\n",
    "if not os.path.isfile(csv_fn):\n",
    "    !wget -r -l1 --no-parent  -P {local_folder} -A \"daily_volume_{year}*.xlsx\" ftp://ftp.cmegroup.com/daily_volume/\n",
    "    !mv {local_folder}/ftp.cmegroup.com/daily_volume/*.xlsx {local_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Extract the open interest data from the xlsx workbook\n",
    "\n",
    "* This takes a long time, so don't rerun it if you have already created a DataFrame for the year\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(csv_fn):\n",
    "\n",
    "    # get all of the xlsx files\n",
    "    file_names = os.listdir(local_folder)\n",
    "\n",
    "    # Create a place holder for the final DataFrame\n",
    "    df_all_col_data = None\n",
    "\n",
    "    # valid files have 'daily_volume' in the name, \n",
    "    for fn in file_names:\n",
    "        if 'daily_volume' not in fn:\n",
    "            continue\n",
    "        # and valid files have the year that we are currently working on in the name as well\n",
    "        if year not in fn:\n",
    "            continue\n",
    "\n",
    "        # If you get here, you will process the xlsx or xls file\n",
    "        full_path = f'{local_folder}/{fn}'\n",
    "        if len(re.findall('.xls$',full_path)) > 0:\n",
    "            # if the file is an xls file, convert it to xlsx using libreoffice\n",
    "            !/Applications/LibreOffice.app/Contents/MacOS/soffice --convert-to xlsx {full_path} --headless --outdir {local_folder} \n",
    "            full_path = full_path + \"x\"\n",
    "\n",
    "        print(f'processing {full_path} ')\n",
    "\n",
    "        # Get a workbook\n",
    "        wb = load_workbook(filename = full_path)\n",
    "        # Get a worksheet\n",
    "        sheet_ranges = wb['CME Group Vol and OI by Product']\n",
    "        # find Header column by finding Description\n",
    "        first_row = None\n",
    "        for i in range(1,20):\n",
    "            cell_val = sheet_ranges[f'A{str(i)}'].value\n",
    "            if 'description' in str(cell_val).lower():\n",
    "                first_row = str(i)\n",
    "                break\n",
    "        if first_row is None:\n",
    "            print('ERROR: cannot find header column')\n",
    "            break\n",
    "\n",
    "        # Get the column names, and get rid of non-alphabetic characters\n",
    "        data = sheet_ranges[f'A{first_row}:L1000']\n",
    "        cols = ['_'.join(re.findall('[A-Za-z ]{1,}',str(data[0][i].value))) for i in range(12)]\n",
    "        cols = [c.strip().replace(' ','_').replace('__','_') for c in cols]\n",
    "\n",
    "        # Populate col_data, which has all of the data for each column\n",
    "        col_data = []\n",
    "        for j in range(12):\n",
    "            this_col = []\n",
    "            for i in range(1,len(data)):\n",
    "                this_col.append(data[i][j].value)\n",
    "            col_data.append(this_col)\n",
    "\n",
    "        # Create the dictionary of column names and data for creating the DataFrame\n",
    "        dict_for_df = {cols[i]:col_data[i] for i in range(12)}\n",
    "\n",
    "        # Create the DataFrame\n",
    "        df_col_data = pd.DataFrame(dict_for_df) \n",
    "\n",
    "        # Add a trade_date field\n",
    "        df_col_data['trade_date'] = int(re.findall('20[0-9]{2}[0-1][0-9][0-3][0-9]',fn)[0])\n",
    "\n",
    "        # populate df_all_col_data, which is the dataframe that holds all of the open interest data for each day\n",
    "        if df_all_col_data is None:\n",
    "            df_all_col_data = df_col_data.copy()\n",
    "        else:\n",
    "            df_all_col_data = df_all_col_data.append(df_col_data)\n",
    "            \n",
    "    # Save df_all_col_data and save a version just for CL\n",
    "    df_all_col_data.to_csv(f'{temp_folder}/cme_open_interest_{year}.csv',index=False)\n",
    "    df_all_col_data[df_all_col_data.Commodity_Indicator=='CL'].to_csv(f'{temp_folder}/cl_open_interest_{year}.csv',index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create the df_commodity_all_years DataFrame which has CL open interest data for multiple years\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commodity = 'GC'\n",
    "csv_name_template = f'{temp_folder}/cme_open_interest_%s.csv'\n",
    "df_commodity_all_years = None\n",
    "years = [2013,2014,2015,2016,2017,2018,2019]\n",
    "for y in years:\n",
    "    n = csv_name_template %(str(y))\n",
    "    df_temp = pd.read_csv(n)\n",
    "    df_temp = df_temp[df_temp.Commodity_Indicator==commodity]\n",
    "    if df_commodity_all_years is None:\n",
    "        df_commodity_all_years = df_temp.copy()\n",
    "    else:\n",
    "        df_commodity_all_years = df_commodity_all_years.append(df_temp)\n",
    "\n",
    "# make sure it's sorted\n",
    "df_commodity_all_years_sorted = df_commodity_all_years.sort_values(by='trade_date')\n",
    "df_commodity_all_years_sorted.index = range(len(df_commodity_all_years_sorted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Create a method that Plots Commodity open interest, and selected ETF\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_open_interest(df_in,num_of_x_ticks=20):\n",
    "    df_cl = df_in[['trade_date','Open_Interest','etf']]\n",
    "    df_cl = df_cl[~df_cl.Open_Interest.isnull()]\n",
    "    df_cl.Open_Interest = df_cl.Open_Interest.astype(float).astype(int)\n",
    "    \n",
    "    df_cl = df_cl.drop_duplicates()\n",
    "    xs = list(df_cl.trade_date)\n",
    "    df_cl['trade_date'] = df_cl.trade_date.apply(lambda i:str(i))\n",
    "\n",
    "    x = list(range(len(df_cl)))\n",
    "    n = len(x)\n",
    "    s = num_of_x_ticks\n",
    "    k = n//s*s\n",
    "    x_indices = x[::-1][:k][::k//s][::-1]\n",
    "    x_labels = [str(t) for t in list(df_cl.iloc[x_indices].trade_date)]\n",
    "    y = list(df_cl.Open_Interest)[x_indices[0]:]\n",
    "    y2 = list(df_cl['etf'])[x_indices[0]:]\n",
    "    x = x[x_indices[0]:]\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "    ax.grid(color='lightgray', alpha=0.7)\n",
    "\n",
    "    ax.plot(x,y,'b-')\n",
    "    ax.set_ylabel(\"Open Interest\")\n",
    "    ax.tick_params('y', colors='b')\n",
    "    plt.xticks(x_indices, x_labels, rotation='vertical')\n",
    "    plt.subplots_adjust(bottom=0.20)\n",
    "    plt.xticks(rotation=60)\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(x,y2,'r-',)\n",
    "    ax2.set_title(\"ETF NAV vs Open Interest\")\n",
    "    ax2.set_ylabel(\"ETF NAV\")    \n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REFRESH_ETF_PRICES:\n",
    "    for commod in EXAMPLE_COMMODITY_ETFS:\n",
    "        dfe = web.DataReader(commod, 'yahoo', dt.datetime(2016, 1, 1), dt.datetime.now())\n",
    "        dfe['Date'] = dfe.index\n",
    "        dfe.index  = list(range(len(dfe)))\n",
    "        dfe['trade_date'] = dfe.Date.apply(lambda s:int(str(s)[0:4]+str(s)[5:7]+str(s)[8:10]))\n",
    "        dfe = dfe[['Date','Open','High','Low','Close','Adj Close','Volume','trade_date']]\n",
    "        dfe.to_csv(f'{commod}_daily.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_path = 'gld_daily.csv'\n",
    "df_etf_daily = pd.read_csv(etf_path)\n",
    "df_etf_daily = df_etf_daily.drop_duplicates()\n",
    "df_etf_daily['trade_date'] = df_etf_daily.Date.apply(lambda s: int(s[0:4]+s[5:7]+s[8:10]))\n",
    "df_etf_daily2 = df_etf_daily.sort_values(by='trade_date')\n",
    "df_etf_daily3 = df_etf_daily2[['trade_date','Adj Close']].rename(columns={'Adj Close':'etf'})\n",
    "df_commodity_all_years_with_etf = df_commodity_all_years_sorted.merge(df_etf_daily3,how='inner',on='trade_date')\n",
    "df_commodity_all_years_with_etf.trade_date = df_commodity_all_years_with_etf.trade_date.astype(int)\n",
    "df_commodity_all_years_with_etf = df_commodity_all_years_with_etf.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_open_interest(df_commodity_all_years_with_etf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute a zoomed in version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_yyyymmdd = 20180801\n",
    "end_yyyymmdd = 20181001\n",
    "c1= df_commodity_all_years_with_etf.trade_date>=beg_yyyymmdd\n",
    "c2 = df_commodity_all_years_with_etf.trade_date<=end_yyyymmdd\n",
    "c_all = (c1 & c2)\n",
    "df_sub = df_commodity_all_years_with_etf[c_all][[\n",
    "    'trade_date','Open_Interest','etf']].drop_duplicates()\n",
    "plot_open_interest(df_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
